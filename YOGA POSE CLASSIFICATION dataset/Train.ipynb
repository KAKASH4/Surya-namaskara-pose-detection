{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOFry32gnAbA3W9P1RC18vS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lfo-xwadzC5g","executionInfo":{"status":"ok","timestamp":1712128179847,"user_tz":-330,"elapsed":35364,"user":{"displayName":"k Akash","userId":"10267186837181628124"}},"outputId":"4653ab8b-70d7-4384-ba5f-c90f6ef4725e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["!ls '/content/gdrive/My Drive/YOGA POSE CLASSIFICATION/val'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEjf_C621bXt","executionInfo":{"status":"ok","timestamp":1712128187598,"user_tz":-330,"elapsed":1841,"user":{"displayName":"k Akash","userId":"10267186837181628124"}},"outputId":"d5116a05-4664-43f6-8369-4fbdd098e6b0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Ardhachakrasana    Astangasana\t Dandasana\t Parvathasana  Shashangasana\n","Ashwasanchalasana  Bhujangasana  Padhahastasana  Pranamasana\n"]}]},{"cell_type":"code","source":["DATA_DIR='/content/gdrive/My Drive/YOGA POSE CLASSIFICATION/'"],"metadata":{"id":"xgN61EC-1vY2","executionInfo":{"status":"ok","timestamp":1712128190370,"user_tz":-330,"elapsed":5,"user":{"displayName":"k Akash","userId":"10267186837181628124"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tgvwHc7S2zh3","executionInfo":{"status":"ok","timestamp":1712128276741,"user_tz":-330,"elapsed":83511,"user":{"displayName":"k Akash","userId":"10267186837181628124"}},"outputId":"9189406b-84ab-4f7c-a9b5-2efced8a3256"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.1.42-py3-none-any.whl (749 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/749.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.3/749.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m749.1/749.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.1.42\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO"],"metadata":{"id":"gZ-jykBjZ4fv","executionInfo":{"status":"ok","timestamp":1712128323384,"user_tz":-330,"elapsed":7063,"user":{"displayName":"k Akash","userId":"10267186837181628124"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","from ultralytics import YOLO\n","\n","model=YOLO('yolov8n-cls.pt')\n","\n","results = model.train(data=DATA_DIR,epochs=20,imgsz=224)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nKZQ-PN83KWa","executionInfo":{"status":"ok","timestamp":1709179445614,"user_tz":-330,"elapsed":508869,"user":{"displayName":"k Akash","userId":"10267186837181628124"}},"outputId":"575b8e2a-2452-45d2-cf09-4c92270f4a48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.19 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/gdrive/My Drive/YOGA POSE CLASSIFICATION/, epochs=20, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train2\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/gdrive/My Drive/YOGA POSE CLASSIFICATION/train... found 369 images in 9 classes ✅ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/gdrive/My Drive/YOGA POSE CLASSIFICATION/val... found 27 images in 9 classes ✅ \n","\u001b[34m\u001b[1mtest:\u001b[0m None...\n","Overriding model.yaml nc=1000 with nc=9\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    341769  ultralytics.nn.modules.head.Classify         [256, 9]                      \n","YOLOv8n-cls summary: 99 layers, 1449817 parameters, 1449817 gradients, 3.4 GFLOPs\n","Transferred 156/158 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train2', view at http://localhost:6006/\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/YOGA POSE CLASSIFICATION/train... 369 images, 0 corrupt: 100%|██████████| 369/369 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/YOGA POSE CLASSIFICATION/val... 27 images, 0 corrupt: 100%|██████████| 27/27 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 224 train, 224 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/classify/train2\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/20         0G      2.236          1        224: 100%|██████████| 24/24 [00:28<00:00,  1.20s/it]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.148      0.741\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/20         0G      2.079          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.00it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.407      0.852\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/20         0G       1.77          1        224: 100%|██████████| 24/24 [00:24<00:00,  1.01s/it]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all       0.63      0.926\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/20         0G      1.437          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.00it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.778      0.963\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/20         0G      1.097          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.852          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/20         0G     0.8562          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.03it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.815          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","       7/20         0G     0.6639          1        224: 100%|██████████| 24/24 [00:27<00:00,  1.13s/it]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.889          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","       8/20         0G     0.5403          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.889          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/20         0G     0.4704          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.03it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.852          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","      10/20         0G     0.4026          1        224: 100%|██████████| 24/24 [00:22<00:00,  1.05it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.926          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/20         0G     0.3658          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.03it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.963          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","      12/20         0G     0.3296          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.02it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.889          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","      13/20         0G     0.3106          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.02it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.926          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","      14/20         0G     0.3281          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.02it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.889          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","      15/20         0G     0.2908          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.889          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","      16/20         0G     0.3056          1        224: 100%|██████████| 24/24 [00:22<00:00,  1.05it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.889          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","      17/20         0G     0.2466          1        224: 100%|██████████| 24/24 [00:22<00:00,  1.05it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.889          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","      18/20         0G     0.2414          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.02it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.926          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","      19/20         0G     0.2239          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.02it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.926          1\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["\n","      20/20         0G     0.2789          1        224: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.926          1\n","\n","20 epochs completed in 0.139 hours.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Optimizer stripped from runs/classify/train2/weights/last.pt, 3.0MB\n","Optimizer stripped from runs/classify/train2/weights/best.pt, 3.0MB\n","\n","Validating runs/classify/train2/weights/best.pt...\n","Ultralytics YOLOv8.1.19 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n","YOLOv8n-cls summary (fused): 73 layers, 1446409 parameters, 0 gradients, 3.3 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/gdrive/My Drive/YOGA POSE CLASSIFICATION/train... found 369 images in 9 classes ✅ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/gdrive/My Drive/YOGA POSE CLASSIFICATION/val... found 27 images in 9 classes ✅ \n","\u001b[34m\u001b[1mtest:\u001b[0m None...\n"]},{"output_type":"stream","name":"stderr","text":["               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      0.963          1\n","Speed: 0.0ms preprocess, 10.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/train2\u001b[0m\n","Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"]}]},{"cell_type":"code","source":["!scp -r /content/runs '/content/gdrive/My Drive'"],"metadata":{"id":"w-Fz42Fb4A6z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls '/content/gdrive/My Drive/runs/classify/train/weights'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y3DOy9ZYb8Ks","executionInfo":{"status":"ok","timestamp":1709202614030,"user_tz":-330,"elapsed":841,"user":{"displayName":"k Akash","userId":"10267186837181628124"}},"outputId":"dcfbf975-a268-43fe-e724-bd45f3171913"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access '/content/gdrive/My Drive/runs/classify/train/weights': No such file or directory\n"]}]},{"cell_type":"code","source":["model = YOLO('/content/gdrive/My Drive/runs/classify/train2/weights/best.pt')  # load a custom model\n","\n","results = model('/content/gdrive/My Drive/pranam.jpg')\n","\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jaV7tRPub4eM","executionInfo":{"status":"ok","timestamp":1712128568642,"user_tz":-330,"elapsed":720,"user":{"displayName":"k Akash","userId":"10267186837181628124"}},"outputId":"edc8c7e9-3488-4d34-fe93-6dd6302e2272"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/gdrive/My Drive/pranam.jpg: 224x224 Pranamasana 0.97, Ashwasanchalasana 0.02, Dandasana 0.01, Bhujangasana 0.00, Ardhachakrasana 0.00, 12.6ms\n","Speed: 27.1ms preprocess, 12.6ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n","[ultralytics.engine.results.Results object with attributes:\n","\n","boxes: None\n","keypoints: None\n","masks: None\n","names: {0: 'Ardhachakrasana', 1: 'Ashwasanchalasana', 2: 'Astangasana', 3: 'Bhujangasana', 4: 'Dandasana', 5: 'Padhahastasana', 6: 'Parvathasana', 7: 'Pranamasana', 8: 'Shashangasana'}\n","obb: None\n","orig_img: array([[[195, 210, 212],\n","        [195, 210, 212],\n","        [195, 210, 212],\n","        ...,\n","        [165, 184, 189],\n","        [165, 184, 189],\n","        [165, 184, 189]],\n","\n","       [[195, 210, 212],\n","        [195, 210, 212],\n","        [195, 210, 212],\n","        ...,\n","        [165, 184, 189],\n","        [165, 184, 189],\n","        [165, 184, 189]],\n","\n","       [[195, 210, 212],\n","        [195, 210, 212],\n","        [195, 210, 212],\n","        ...,\n","        [165, 184, 189],\n","        [165, 184, 189],\n","        [165, 184, 189]],\n","\n","       ...,\n","\n","       [[124, 121, 170],\n","        [120, 120, 168],\n","        [114, 116, 164],\n","        ...,\n","        [105, 131, 137],\n","        [107, 133, 139],\n","        [108, 134, 140]],\n","\n","       [[124, 121, 170],\n","        [119, 119, 167],\n","        [114, 116, 164],\n","        ...,\n","        [105, 131, 137],\n","        [107, 133, 139],\n","        [108, 134, 140]],\n","\n","       [[123, 120, 169],\n","        [119, 119, 167],\n","        [114, 116, 164],\n","        ...,\n","        [105, 131, 137],\n","        [107, 133, 139],\n","        [108, 134, 140]]], dtype=uint8)\n","orig_shape: (1156, 652)\n","path: '/content/gdrive/My Drive/pranam.jpg'\n","probs: ultralytics.engine.results.Probs object\n","save_dir: 'runs/classify/predict'\n","speed: {'preprocess': 27.080059051513672, 'inference': 12.600183486938477, 'postprocess': 0.09608268737792969}]\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","# Load pre-trained EfficientNet-B0 model without top classification layer\n","base_model = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False)\n","\n","# Freeze base model layers\n","base_model.trainable = False\n","\n","# Add new classification layers\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(1024, activation='relu')(x)  # Customize the number of units as needed\n","predictions = Dense(9, activation='softmax')(x)  # Adjust num_classes to the number of classes in your dataset\n","\n","# Create final model\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Compile model\n","model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Data generators for training and validation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    '/content/gdrive/My Drive/YOGA POSE CLASSIFICATION/train',\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    '/content/gdrive/My Drive/YOGA POSE CLASSIFICATION/val',\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='categorical')\n","\n","# Train the model\n","model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // 16,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // 16,\n","    epochs=30)\n","\n","# Save the trained model\n","model.save('yoga_pose_classification_model.h5')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l607BUE2mrxG","executionInfo":{"status":"ok","timestamp":1710143648363,"user_tz":-330,"elapsed":234089,"user":{"displayName":"k Akash","userId":"10267186837181628124"}},"outputId":"df916217-dbd7-4cbb-8fd1-0fda76b51c6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 369 images belonging to 9 classes.\n","Found 27 images belonging to 9 classes.\n","Epoch 1/30\n","23/23 [==============================] - 23s 685ms/step - loss: 2.3443 - accuracy: 0.1076 - val_loss: 2.3439 - val_accuracy: 0.1250\n","Epoch 2/30\n","23/23 [==============================] - 6s 262ms/step - loss: 2.2439 - accuracy: 0.1161 - val_loss: 2.2969 - val_accuracy: 0.1250\n","Epoch 3/30\n","23/23 [==============================] - 6s 245ms/step - loss: 2.2316 - accuracy: 0.1020 - val_loss: 2.2595 - val_accuracy: 0.1250\n","Epoch 4/30\n","23/23 [==============================] - 6s 254ms/step - loss: 2.2076 - accuracy: 0.1275 - val_loss: 2.2524 - val_accuracy: 0.1250\n","Epoch 5/30\n","23/23 [==============================] - 7s 278ms/step - loss: 2.2448 - accuracy: 0.1020 - val_loss: 2.1746 - val_accuracy: 0.1875\n","Epoch 6/30\n","23/23 [==============================] - 7s 288ms/step - loss: 2.1988 - accuracy: 0.1416 - val_loss: 2.2026 - val_accuracy: 0.1250\n","Epoch 7/30\n","23/23 [==============================] - 6s 244ms/step - loss: 2.2063 - accuracy: 0.1020 - val_loss: 2.2065 - val_accuracy: 0.0625\n","Epoch 8/30\n","23/23 [==============================] - 7s 292ms/step - loss: 2.1977 - accuracy: 0.1360 - val_loss: 2.1983 - val_accuracy: 0.1250\n","Epoch 9/30\n","23/23 [==============================] - 6s 248ms/step - loss: 2.1939 - accuracy: 0.0935 - val_loss: 2.2293 - val_accuracy: 0.1250\n","Epoch 10/30\n","23/23 [==============================] - 7s 297ms/step - loss: 2.1929 - accuracy: 0.1388 - val_loss: 2.2020 - val_accuracy: 0.1250\n","Epoch 11/30\n","23/23 [==============================] - 6s 241ms/step - loss: 2.1971 - accuracy: 0.1416 - val_loss: 2.1479 - val_accuracy: 0.1875\n","Epoch 12/30\n","23/23 [==============================] - 7s 292ms/step - loss: 2.1949 - accuracy: 0.1303 - val_loss: 2.1879 - val_accuracy: 0.1250\n","Epoch 13/30\n","23/23 [==============================] - 6s 247ms/step - loss: 2.1914 - accuracy: 0.1360 - val_loss: 2.2116 - val_accuracy: 0.0625\n","Epoch 14/30\n","23/23 [==============================] - 7s 316ms/step - loss: 2.1924 - accuracy: 0.1388 - val_loss: 2.2118 - val_accuracy: 0.0000e+00\n","Epoch 15/30\n","23/23 [==============================] - 7s 293ms/step - loss: 2.1919 - accuracy: 0.1218 - val_loss: 2.1925 - val_accuracy: 0.1250\n","Epoch 16/30\n","23/23 [==============================] - 6s 240ms/step - loss: 2.1936 - accuracy: 0.1161 - val_loss: 2.2071 - val_accuracy: 0.1250\n","Epoch 17/30\n","23/23 [==============================] - 7s 291ms/step - loss: 2.1894 - accuracy: 0.1416 - val_loss: 2.2239 - val_accuracy: 0.1250\n","Epoch 18/30\n","23/23 [==============================] - 6s 244ms/step - loss: 2.1955 - accuracy: 0.1275 - val_loss: 2.1867 - val_accuracy: 0.1250\n","Epoch 19/30\n","23/23 [==============================] - 7s 289ms/step - loss: 2.1889 - accuracy: 0.1331 - val_loss: 2.2190 - val_accuracy: 0.1250\n","Epoch 20/30\n","23/23 [==============================] - 6s 240ms/step - loss: 2.1914 - accuracy: 0.1445 - val_loss: 2.1747 - val_accuracy: 0.1250\n","Epoch 21/30\n","23/23 [==============================] - 6s 272ms/step - loss: 2.1908 - accuracy: 0.1275 - val_loss: 2.1755 - val_accuracy: 0.1875\n","Epoch 22/30\n","23/23 [==============================] - 6s 247ms/step - loss: 2.1989 - accuracy: 0.1388 - val_loss: 2.2409 - val_accuracy: 0.1875\n","Epoch 23/30\n","23/23 [==============================] - 6s 240ms/step - loss: 2.1925 - accuracy: 0.1246 - val_loss: 2.1909 - val_accuracy: 0.1250\n","Epoch 24/30\n","23/23 [==============================] - 7s 296ms/step - loss: 2.1909 - accuracy: 0.1388 - val_loss: 2.1760 - val_accuracy: 0.1875\n","Epoch 25/30\n","23/23 [==============================] - 6s 251ms/step - loss: 2.1936 - accuracy: 0.1360 - val_loss: 2.2296 - val_accuracy: 0.0625\n","Epoch 26/30\n","23/23 [==============================] - 7s 295ms/step - loss: 2.1927 - accuracy: 0.1388 - val_loss: 2.1875 - val_accuracy: 0.0625\n","Epoch 27/30\n","23/23 [==============================] - 6s 256ms/step - loss: 2.1937 - accuracy: 0.1360 - val_loss: 2.2084 - val_accuracy: 0.1250\n","Epoch 28/30\n","23/23 [==============================] - 6s 244ms/step - loss: 2.1922 - accuracy: 0.1388 - val_loss: 2.1961 - val_accuracy: 0.1875\n","Epoch 29/30\n","23/23 [==============================] - 7s 292ms/step - loss: 2.1910 - accuracy: 0.1246 - val_loss: 2.1778 - val_accuracy: 0.1875\n","Epoch 30/30\n","23/23 [==============================] - 6s 247ms/step - loss: 2.1912 - accuracy: 0.1218 - val_loss: 2.1985 - val_accuracy: 0.0625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]}]}